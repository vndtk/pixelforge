This files contains instructions to implement rarity calculations for minted NFTs.
The rarity step belongs in the “prepare metadata for Arweave” phase, most likely in:

lib/prepare-mint-data.ts

That file should be your single place where you:

– Receive pixel data / image URL
– Prepare the JSON for Arweave
– Attach attributes[] for the NFT

We just extend that step to compute rarity and append it.

Compute a continuous “quality score” and then scale the probabilities.

Step A: normalize stats

pixelsUsed: 0 to 1024

colorsUsed: 0 to 16

function computeScore(pixelsUsed: number, colorsUsed: number) {
  const pixelFactor = Math.min(pixelsUsed / 1024, 1);  // 0..1
  const colorFactor = Math.min(colorsUsed / 16, 1);    // 0..1

  // weight pixels more than colors if you want
  const score = (0.7 * pixelFactor + 0.3 * colorFactor); // 0..1
  return score;
}


Step B: define base probabilities

const BASE_PROBS: RarityTable = {
  Common: 0.6,
  Uncommon: 0.25,
  Rare: 0.1,
  Epic: 0.04,
  Legendary: 0.01,
};


Step C: define how much each tier gets boosted as score → 1.
Example idea:

Common gets slightly penalized

Uncommon small boost

Rare/Epic/Legendary big boost

const BOOST_WEIGHTS: Record<RarityTier, number> = {
  Common: -0.4,     // negative = downweight as score increases
  Uncommon: 0.2,
  Rare: 0.6,
  Epic: 1.0,
  Legendary: 1.5,
};


Now compute adjusted probabilities:

function computeProbabilities(pixelsUsed: number, colorsUsed: number): RarityTable {
  const score = computeScore(pixelsUsed, colorsUsed); // 0..1

  // 1 + score * weight
  // At score=0: factor ~1
  // At score=1: factor ~1 + weight
  const raw: Record<RarityTier, number> = {
    Common: BASE_PROBS.Common * (1 + score * BOOST_WEIGHTS.Common),
    Uncommon: BASE_PROBS.Uncommon * (1 + score * BOOST_WEIGHTS.Uncommon),
    Rare: BASE_PROBS.Rare * (1 + score * BOOST_WEIGHTS.Rare),
    Epic: BASE_PROBS.Epic * (1 + score * BOOST_WEIGHTS.Epic),
    Legendary: BASE_PROBS.Legendary * (1 + score * BOOST_WEIGHTS.Legendary),
  };

  // guard: avoid negative
  for (const tier of Object.keys(raw) as RarityTier[]) {
    if (raw[tier] < 0) raw[tier] = 0;
  }

  const sum = Object.values(raw).reduce((a, b) => a + b, 0) || 1;

  const normalized: RarityTable = {
    Common: raw.Common / sum,
    Uncommon: raw.Uncommon / sum,
    Rare: raw.Rare / sum,
    Epic: raw.Epic / sum,
    Legendary: raw.Legendary / sum,
  };

  return normalized;
}

function rollRarityWithScore(pixelsUsed: number, colorsUsed: number): RarityTier {
  const probs = computeProbabilities(pixelsUsed, colorsUsed);
  const r = Math.random();
  let cumulative = 0;
  for (const tier of ["Common","Uncommon","Rare","Epic","Legendary"] as RarityTier[]) {
    cumulative += probs[tier];
    if (r < cumulative) return tier;
  }
  return "Common";
}


What this gives you:

At low pixelsUsed/colorsUsed → probabilities close to BASE_PROBS

At max pixelsUsed/colorsUsed → Common shrinks, Rare/Epic/Legendary expand